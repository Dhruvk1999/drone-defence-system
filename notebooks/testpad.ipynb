{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61279c28",
   "metadata": {},
   "source": [
    "# Some tutorials\n",
    "<a href=\"https://towardsdatascience.com/object-detection-explained-r-cnn-a6c813937a76\"> region proposal using r-cnn</a>\n",
    "\n",
    "<a href=\"https://learnopencv.com/selective-search-for-object-detection-cpp-python/\"> region proposal using selective segmentation</a>\n",
    "\n",
    "https://github.com/chingisooinar/Object-Detection_from-Scratch/blob/main/RCNN/RCNN.ipynb\n",
    "\n",
    "<a href=\"https://towardsdatascience.com/step-by-step-r-cnn-implementation-from-scratch-in-python-e97101ccde55\">RCNN-implemenation</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e562805b",
   "metadata": {},
   "source": [
    "# Selective selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2058ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dhruv\n"
     ]
    }
   ],
   "source": [
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf134033",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/dhruv'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ae5478d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dhruv/drone-defense-wall/data\n"
     ]
    }
   ],
   "source": [
    "cd drone-defense-wall/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2d4ae54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "453bc505",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@4.850] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('265.JPG'): can't open/read file: check file path/integrity\n"
     ]
    }
   ],
   "source": [
    "im = cv2.imread(\"265.JPG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8a9c219",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@16.865] global /io/opencv/modules/imgcodecs/src/loadsave.cpp (239) findDecoder imread_('265.JPG'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6821/1414896025.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# resize image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mnewHeight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mnewWidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnewWidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewHeight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "'''\n",
    "Usage:\n",
    "./ssearch.py input_image (f|q)\n",
    "f=fast, q=quality\n",
    "Use \"l\" to display less rects, 'm' to display more rects, \"q\" to quit.\n",
    "'''\n",
    "\n",
    "import sys\n",
    "import cv2\n",
    "\n",
    "\n",
    "# If image path and f/q is not passed as command\n",
    "# line arguments, quit and display help message\n",
    "if len(sys.argv) < 3:\n",
    "    print(__doc__)\n",
    "    sys.exit(1)\n",
    "\n",
    "# speed-up using multithreads\n",
    "cv2.setUseOptimized(True);\n",
    "cv2.setNumThreads(4);\n",
    "\n",
    "# read image\n",
    "im = cv2.imread(\"265.JPG\")\n",
    "# resize image\n",
    "newHeight = 200\n",
    "newWidth = int(im.shape[1]*200/im.shape[0])\n",
    "im = cv2.resize(im, (newWidth, newHeight))    \n",
    "\n",
    "# create Selective Search Segmentation Object using default parameters\n",
    "ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\n",
    "\n",
    "# set input image on which we will run segmentation\n",
    "ss.setBaseImage(im)\n",
    "\n",
    "# Switch to fast but low recall Selective Search method\n",
    "#if (sys.argv[2] == 'f'):\n",
    "ss.switchToSelectiveSearchFast()\n",
    "\n",
    "# Switch to high recall but slow Selective Search method\n",
    "# elif (sys.argv[2] == 'q'):\n",
    "#     ss.switchToSelectiveSearchQuality()\n",
    "# # if argument is neither f nor q print help message\n",
    "# else:\n",
    "#     print(__doc__)\n",
    "#     sys.exit(1)\n",
    "\n",
    "# run selective search segmentation on input image\n",
    "rects = ss.process()\n",
    "\n",
    "# taking only the upper 2/3rd of the image\n",
    "bboxes=[]\n",
    "for x,y,w,h in rects:\n",
    "    if y<100:\n",
    "        bboxes.append([x,y,w,h])\n",
    "bboxes=np.array(bboxes)\n",
    "rects=bboxes\n",
    "print('Total Number of Region Proposals: {}'.format(len(rects)))\n",
    "\n",
    "# number of region proposals to show\n",
    "numShowRects = 80\n",
    "# increment to increase/decrease total number\n",
    "# of reason proposals to be shown\n",
    "increment = 10\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "while True:\n",
    "    # create a copy of original image\n",
    "    imOut = im.copy()\n",
    "\n",
    "    # itereate over all the region proposals\n",
    "    for i, rect in enumerate(rects):\n",
    "        # draw rectangle for region proposal till numShowRects\n",
    "        if (i < numShowRects):\n",
    "            x, y, w, h = rect\n",
    "            cv2.rectangle(imOut, (x, y), (x+w, y+h), (0, 255, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # show output\n",
    "    cv2.imshow(\"Output\", imOut)\n",
    "\n",
    "    # record key press\n",
    "    k = cv2.waitKey(0) & 0xFF\n",
    "\n",
    "    # m is pressed\n",
    "    if k == 109:\n",
    "        # increase total number of rectangles to show by increment\n",
    "        numShowRects += increment\n",
    "    # l is pressed\n",
    "    elif k == 108 and numShowRects > increment:\n",
    "        # decrease total number of rectangles to show by increment\n",
    "        numShowRects -= increment\n",
    "    # q is pressed\n",
    "    elif k == 113:\n",
    "        break\n",
    "# close image show window\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a55f91c",
   "metadata": {},
   "source": [
    "# Object Tracking\n",
    "- using boosting and median tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e8312a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "519dcc8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dhruv\n"
     ]
    }
   ],
   "source": [
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e43bb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cd openCV-practice/Computer-Vision-with-Python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c462528",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_for_tracker():\n",
    "    print(\"Welcome! What Tracker API would you like to use?\")\n",
    "    print(\"Enter 0 for BOOSTING: \")\n",
    "    print(\"Enter 1 for MIL: \")\n",
    "    print(\"Enter 2 for KCF: \")\n",
    "    print(\"Enter 3 for TLD: \")\n",
    "    print(\"Enter 4 for MEDIANFLOW: \")\n",
    "    choice = input(\"\")\n",
    "    \n",
    "    if choice == '0':\n",
    "        tracker = cv2.legacy.TrackerBoosting_create()\n",
    "    if choice == '1':\n",
    "        tracker = cv2.legacy.TrackerMIL_create()\n",
    "    if choice == '2':\n",
    "        tracker = cv2.legacy.TrackerKCF_create()\n",
    "    if choice == '3':\n",
    "        tracker = cv2.legacy.TrackerTLD_create()\n",
    "    if choice == '4':\n",
    "        tracker = cv2.legacy.TrackerMedianFlow_create()\n",
    "\n",
    "\n",
    "    return tracker\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "730b70f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome! What Tracker API would you like to use?\n",
      "Enter 0 for BOOSTING: \n",
      "Enter 1 for MIL: \n",
      "Enter 2 for KCF: \n",
      "Enter 3 for TLD: \n",
      "Enter 4 for MEDIANFLOW: \n",
      "4\n"
     ]
    }
   ],
   "source": [
    "tracker = ask_for_tracker()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "7d1504cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome! What Tracker API would you like to use?\n",
      "Enter 0 for BOOSTING: \n",
      "Enter 1 for MIL: \n",
      "Enter 2 for KCF: \n",
      "Enter 3 for TLD: \n",
      "Enter 4 for MEDIANFLOW: \n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(201, 84) and (294, 143)\n",
      "(205, 85) and (298, 144)\n",
      "(207, 86) and (300, 145)\n",
      "(207, 86) and (300, 145)\n",
      "(206, 86) and (299, 145)\n",
      "(207, 86) and (300, 145)\n",
      "(206, 86) and (299, 145)\n",
      "(206, 87) and (299, 146)\n",
      "(206, 89) and (299, 148)\n",
      "(207, 86) and (300, 145)\n",
      "(206, 88) and (299, 147)\n",
      "(206, 86) and (299, 145)\n",
      "(206, 87) and (299, 146)\n",
      "(207, 86) and (300, 145)\n",
      "(207, 89) and (300, 148)\n",
      "(209, 89) and (302, 148)\n",
      "(207, 86) and (300, 145)\n",
      "(207, 86) and (300, 145)\n",
      "(210, 89) and (303, 148)\n",
      "(207, 88) and (300, 147)\n",
      "(208, 89) and (301, 148)\n",
      "(206, 88) and (299, 147)\n",
      "(209, 89) and (302, 148)\n",
      "(207, 89) and (300, 148)\n",
      "(208, 89) and (301, 148)\n",
      "(209, 89) and (302, 148)\n",
      "(210, 90) and (303, 149)\n",
      "(210, 89) and (303, 148)\n",
      "(210, 89) and (303, 148)\n",
      "(210, 89) and (303, 148)\n",
      "(210, 89) and (303, 148)\n",
      "(213, 91) and (306, 150)\n",
      "(210, 89) and (303, 148)\n",
      "(210, 89) and (303, 148)\n",
      "(210, 89) and (303, 148)\n",
      "(210, 89) and (303, 148)\n",
      "(210, 89) and (303, 148)\n",
      "(209, 89) and (302, 148)\n",
      "(210, 89) and (303, 148)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "tracker = ask_for_tracker()\n",
    "tracker_name = str(tracker).split()[0][1:]\n",
    "\n",
    "# Read video\n",
    "cap = cv2.VideoCapture(\"statue.avi\")\n",
    "\n",
    "# Read first frame.\n",
    "ret, frame = cap.read()\n",
    "\n",
    "\n",
    "# Special function allows us to draw on the very first frame our desired ROI\n",
    "## replace this roi by the coordinates from the resultant image from the DL model resultant\n",
    "roi = coor\n",
    "# Initialize tracker with first frame and bounding box\n",
    "ret = tracker.init(frame, roi)\n",
    "\n",
    "writer = cv2.VideoWriter('student_capture.mp4', cv2.VideoWriter_fourcc(*'XVID'),25, (500, 500))\n",
    "\n",
    "\n",
    "while True:\n",
    "    # Read a new frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    \n",
    "    # Update tracker\n",
    "    success, roi = tracker.update(frame)\n",
    "    \n",
    "    # roi variable is a tuple of 4 floats\n",
    "    # We need each value and we need them as integers\n",
    "    (x,y,w,h) = tuple(map(int,roi))\n",
    "    \n",
    "    # Draw Rectangle as Tracker moves\n",
    "    if success:\n",
    "        # Tracking success\n",
    "        p1 = (x, y)\n",
    "        p2 = (x+w, y+h)\n",
    "        cv2.rectangle(frame, p1, p2, (0,255,0), 3)\n",
    "        #print(f'{p1} and {p2}')\n",
    "    else :\n",
    "        # Tracking failure\n",
    "        cv2.putText(frame, \"Failure to Detect Tracking!!\", (100,200), cv2.FONT_HERSHEY_SIMPLEX, 1,(0,0,255),3)\n",
    "\n",
    "    # Display tracker type on frame\n",
    "    cv2.putText(frame, tracker_name, (20,400), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0),3);\n",
    "    \n",
    "    writer.write(frame)\n",
    "\n",
    "\n",
    "    # Display result\n",
    "    cv2.imshow(tracker_name, frame)\n",
    "\n",
    "    # Exit if ESC pressed\n",
    "    k = cv2.waitKey(1) & 0xff\n",
    "    if k == 27 : \n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# use tracker 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c76209",
   "metadata": {},
   "source": [
    "## To-do modifying the above code to take in corrdinates from the DL model resultant image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8db11a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dhruv/drone-defense-wall/darknet\n"
     ]
    }
   ],
   "source": [
    "cd drone-defense-wall/darknet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e8f5d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "00eb1177",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# saving the coordinates to varibles\n",
    "with open('result.txt') as f:\n",
    "    lines = f.readlines()\n",
    "a=lines[-2]\n",
    "b=a.split()\n",
    "left_x=int(b[3])\n",
    "top_y=int(b[5])\n",
    "width=int(b[7])\n",
    "height=int(re.findall(\"^\\d\\d\",b[9])[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a3e3d75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dhruv\n"
     ]
    }
   ],
   "source": [
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2cc49880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "30210e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dhruv/drone-defense-wall\n"
     ]
    }
   ],
   "source": [
    "cd drone-defense-wall/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "5a7e81fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome! What Tracker API would you like to use?\n",
      "Enter 0 for BOOSTING: \n",
      "Enter 1 for MIL: \n",
      "Enter 2 for KCF: \n",
      "Enter 3 for TLD: \n",
      "Enter 4 for MEDIANFLOW: \n",
      "1\n",
      "Read a new frame:  True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x44495658/'XVID' is not supported with codec id 12 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "tracker = ask_for_tracker()\n",
    "tracker_name = str(tracker).split()[0][1:]\n",
    "\n",
    "# Read video\n",
    "cap = cv2.VideoCapture(0)\n",
    "success,image = cap.read()\n",
    "count = 0\n",
    "if success:\n",
    "    cv2.imwrite(\"frame%d.jpg\" % count, image)     # save frame as JPEG file      \n",
    "    success,image = cap.read()\n",
    "    print('Read a new frame: ', success)\n",
    "# Read first frame.\n",
    "ret, frame = cap.read()\n",
    "\n",
    "\n",
    "# Special function allows us to draw on the very first frame our desired ROI\n",
    "## replace this roi by the coordinates from the resultant image from the DL model resultant\n",
    "roi = coor\n",
    "# Initialize tracker with first frame and bounding box\n",
    "ret = tracker.init(frame, roi)\n",
    "\n",
    "writer = cv2.VideoWriter('student_capture.mp4', cv2.VideoWriter_fourcc(*'XVID'),25, (500, 500))\n",
    "\n",
    "\n",
    "while True:\n",
    "    # Read a new frame\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    \n",
    "    # Update tracker\n",
    "    success, roi = tracker.update(frame)\n",
    "    \n",
    "    # roi variable is a tuple of 4 floats\n",
    "    # We need each value and we need them as integers\n",
    "    (x,y,w,h) = tuple(map(int,roi))\n",
    "    \n",
    "    # Draw Rectangle as Tracker moves\n",
    "    if success:\n",
    "        # Tracking success\n",
    "        p1 = (x, y)\n",
    "        p2 = (x+w, y+h)\n",
    "        cv2.rectangle(frame, p1, p2, (0,255,0), 3)\n",
    "        #print(f'{p1} and {p2}')\n",
    "    else :\n",
    "        # Tracking failure\n",
    "        cv2.putText(frame, \"Failure to Detect Tracking!!\", (100,200), cv2.FONT_HERSHEY_SIMPLEX, 1,(0,0,255),3)\n",
    "\n",
    "    # Display tracker type on frame\n",
    "    cv2.putText(frame, tracker_name, (20,400), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0),3);\n",
    "    \n",
    "    writer.write(frame)\n",
    "\n",
    "\n",
    "    # Display result\n",
    "    cv2.imshow(tracker_name, frame)\n",
    "\n",
    "    # Exit if ESC pressed\n",
    "    k = cv2.waitKey(1) & 0xff\n",
    "    if k == 27 : \n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# use tracker 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bf9807d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[202, 86, 93, 59]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1d02f5ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dhruv\n"
     ]
    }
   ],
   "source": [
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9f12023f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dhruv/drone-defense-wall/darknet\n"
     ]
    }
   ],
   "source": [
    "cd drone-defense-wall/darknet/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c9f744d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " GPU isn't used \n",
      " OpenCV isn't used - data augmentation will be slow \n",
      "mini_batch = 1, batch = 8, time_steps = 1, train = 0 \n",
      "   layer   filters  size/strd(dil)      input                output\n",
      "   0 conv     16       3 x 3/ 1    416 x 416 x   3 ->  416 x 416 x  16 0.150 BF\n",
      "   1 max                2x 2/ 2    416 x 416 x  16 ->  208 x 208 x  16 0.003 BF\n",
      "   2 conv     32       3 x 3/ 1    208 x 208 x  16 ->  208 x 208 x  32 0.399 BF\n",
      "   3 max                2x 2/ 2    208 x 208 x  32 ->  104 x 104 x  32 0.001 BF\n",
      "   4 conv     64       3 x 3/ 1    104 x 104 x  32 ->  104 x 104 x  64 0.399 BF\n",
      "   5 max                2x 2/ 2    104 x 104 x  64 ->   52 x  52 x  64 0.001 BF\n",
      "   6 conv    128       3 x 3/ 1     52 x  52 x  64 ->   52 x  52 x 128 0.399 BF\n",
      "   7 max                2x 2/ 2     52 x  52 x 128 ->   26 x  26 x 128 0.000 BF\n",
      "   8 conv    256       3 x 3/ 1     26 x  26 x 128 ->   26 x  26 x 256 0.399 BF\n",
      "   9 max                2x 2/ 2     26 x  26 x 256 ->   13 x  13 x 256 0.000 BF\n",
      "  10 conv    512       3 x 3/ 1     13 x  13 x 256 ->   13 x  13 x 512 0.399 BF\n",
      "  11 max                2x 2/ 1     13 x  13 x 512 ->   13 x  13 x 512 0.000 BF\n",
      "  12 conv   1024       3 x 3/ 1     13 x  13 x 512 ->   13 x  13 x1024 1.595 BF\n",
      "  13 conv    256       1 x 1/ 1     13 x  13 x1024 ->   13 x  13 x 256 0.089 BF\n",
      "  14 conv    512       3 x 3/ 1     13 x  13 x 256 ->   13 x  13 x 512 0.399 BF\n",
      "  15 conv     18       1 x 1/ 1     13 x  13 x 512 ->   13 x  13 x  18 0.003 BF\n",
      "  16 yolo\n",
      "[yolo] params: iou loss: mse (2), iou_norm: 0.75, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.00\n",
      "  17 route  13 \t\t                           ->   13 x  13 x 256 \n",
      "  18 conv    128       1 x 1/ 1     13 x  13 x 256 ->   13 x  13 x 128 0.011 BF\n",
      "  19 upsample                 2x    13 x  13 x 128 ->   26 x  26 x 128\n",
      "  20 route  19 8 \t                           ->   26 x  26 x 384 \n",
      "  21 conv    256       3 x 3/ 1     26 x  26 x 384 ->   26 x  26 x 256 1.196 BF\n",
      "  22 conv     18       1 x 1/ 1     26 x  26 x 256 ->   26 x  26 x  18 0.006 BF\n",
      "  23 yolo\n",
      "[yolo] params: iou loss: mse (2), iou_norm: 0.75, obj_norm: 1.00, cls_norm: 1.00, delta_norm: 1.00, scale_x_y: 1.00\n",
      "Total BFLOPS 5.448 \n",
      "avg_outputs = 324846 \n",
      "Loading weights from weights/yolo-drone.weights...\n",
      " seen 64, trained: 3624 K-images (56 Kilo-batches_64) \n",
      "Done! Loaded 24 layers from weights-file \n",
      " Detection layer: 16 - type = 28 \n",
      " Detection layer: 23 - type = 28 \n",
      "frame0.jpg: Predicted in 1423.549000 milli-seconds.\n",
      "Drone: 94%\t(left_x:  194   top_y:  227   width:  285   height:  162)\n"
     ]
    }
   ],
   "source": [
    "! ./darknet detector test cfg/drone.data cfg/yolo-drone.cfg weights/yolo-drone.weights -dont_show -ext_output frame0.jpg result.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "db3a10bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "202 86 93 59\n"
     ]
    }
   ],
   "source": [
    "print(left_x, top_y, width, height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bb834872",
   "metadata": {},
   "outputs": [],
   "source": [
    "coor=[left_x, top_y, width, height]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "67e34b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[202, 86, 93, 59]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c4c017",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3431ed87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
